{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping top companies stock details from companiesmarketcap & Yahoo finance \n",
    "### Introduction\n",
    "This project scrapes the web to get the stock details of 100 largest companies trading in US. The stock names are obtained from companiesmarketcap.com website. The stock details for each stock is obtained from 'finance.yahoo.com'.\n",
    "\n",
    "### Project Outline    \n",
    "- We use Webscraping to accomplish this goal. Webscraping is a technique to programatically get and parse the information from a website.\n",
    "- First, We will get N most popular stock symbols from companiesmarketcap.com website, https://companiesmarketcap.com/usa/largest-companies-in-the-usa-by-market-cap/?page=1\n",
    "![](https://i.imgur.com/AHMq49x.png)\n",
    "- Then, We will get the stock information such as price,market value,company name etc from yahoo finance website https://finance.yahoo.com/ for each of the stocks.\n",
    "![](https://i.imgur.com/TyerqTr.png)\n",
    "- Tools used:\n",
    "   - Python/jupyter Notebook \n",
    "   - Python requests package to download the web page\n",
    "   - Python BeautifulSoup package to parse the html page downloaded with the requests package\n",
    "   \n",
    "\n",
    "- Finally, Save the information to a csv file in the folloiwng format:\n",
    "```\n",
    "Company,Symbol,Marketprice,previousClosePrice,changeInPrice,Volume,MarketCap\n",
    "Sundial Growers Inc.,SNDL,0.575,0.6113,-0.04,66243601,1.184B\n",
    "Microsoft Corporation,MSFT,287.93,290.73,-2.8,34264008,2.159T\n",
    "Snap Inc.,SNAP,38.01,39.45,-1.44,23064203,61.74B\n",
    "Robinhood Markets Inc.,HOOD,11.81,12.25,-0.44,19269403,9.869B\n",
    "\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"pramation/webscrape-top-n-stocks\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/pramation/webscrape-top-n-stocks\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/pramation/webscrape-top-n-stocks'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute this to save new versions of the notebook\n",
    "jovian.commit(project=\"webscrape-top-n-stocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries\n",
    "- `requests`, to download web page\n",
    "- `BeautifulSoup` to parse the downloaded HTML page\n",
    "- `pandas` to read the csv file into a dataFrame\n",
    "- `math` to use ceil function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining 'get_url_page' function  to accept URL and return a HTML document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_page(url_link):\n",
    "    '''This accepts an URL as a parameter, \n",
    "       accesses and loads the webpage into a variable\n",
    "       retuns a document of the type BeautifulSoup  '''\n",
    "    \n",
    "    #uses requests function to access and load the web page\n",
    "    stock_page_response=requests.get(url_link)\n",
    "    \n",
    "    if not stock_page_response.ok :\n",
    "        print('Status code for {}: {}'.format(url_link,stock_page_response.status_code))\n",
    "        #raise Exception('Failed to fetch web page ' + url_link)\n",
    "        return ''\n",
    "        \n",
    "    # If the status code is success , the page is sent through html parser and builds a parsed document.\n",
    "    stock_page_doc=BeautifulSoup(stock_page_response.text,'html.parser')\n",
    "    \n",
    "    # Returns a beautifulSoup document.\n",
    "    return stock_page_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining 'get_popular_stocks' function to get N most popular stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_popular_stocks(num_stocks=10):\n",
    "    '''\n",
    "      This functions builds a list of most popular stock symbols.\n",
    "      Returns the list of N number of popular stocks\n",
    "    '''\n",
    "    # Get the number of pages to access based on the number of stocks that need to be processed. each page has 100 stocks\n",
    "    page_numbers=int((lambda x:1 if x<1 else ceil(x/100))(num_stocks))\n",
    "    \n",
    "    stocks_symbols=[]\n",
    "    for page_number in range(1,page_numbers+1):\n",
    "        popular_stocks_url='https://companiesmarketcap.com/usa/largest-companies-in-the-usa-by-market-cap/?page='+str(page_number)+'/'\n",
    "\n",
    "        print(\"Web Page: \",popular_stocks_url)\n",
    "        #Call the function 'get_url_page' and get parsed html document\n",
    "        stocks_symbols_tags=get_url_page(popular_stocks_url).find_all('div',{'class':'company-code'})\n",
    "\n",
    "        # Extract ticker symbol name from the tag 'div' in the document\n",
    "        for stocks_symbols_tag in stocks_symbols_tags:\n",
    "            stocks_symbols.append(stocks_symbols_tag.text.strip())\n",
    "    \n",
    "    #Return the list with N stocks    \n",
    "    return stocks_symbols[:num_stocks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining 'get_name_n_symbol' function to get each stock's details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_n_symbol(companyName):\n",
    "    ''' \n",
    "       A Helper function to accept Name and returns company Name and ticker symbol\n",
    "    '''\n",
    "    cName=companyName.split(\"(\")\n",
    "    return cName[0].strip(),cName[1].strip(')')\n",
    "\n",
    "def get_ticker_details(ticker_symbol):\n",
    "    '''\n",
    "       This function accepts the ticker symbol,\n",
    "       gets the html parsed document, finds appropriate tags and its value(text)\n",
    "       massages the data and returns stocks details as a python Dictionary\n",
    "    '''\n",
    "    \n",
    "    #print(\"Processing : \",ticker_symbol)\n",
    "    ticker_url='https://finance.yahoo.com/quote/'+ticker_symbol\n",
    "    \n",
    "    #get html parsed document. \n",
    "    stock_page_doc=get_url_page(ticker_url)\n",
    "    \n",
    "    if len(stock_page_doc)== 0:\n",
    "        return ''\n",
    "    \n",
    "    #Use find function of BeatufulSoup objet to get the values of the tags\n",
    "       #Use helper function get_name_n_symbol to extract company name and ticker symbol from the h1 name\n",
    "    cName,ticker=get_name_n_symbol(stock_page_doc.h1.text)\n",
    "    MarketPrice=stock_page_doc.find('fin-streamer',{'class':\"Fw(b) Fz(36px) Mb(-4px) D(ib)\",'data-field':\"regularMarketPrice\" }).text.replace(\",\",\"\")\n",
    "    previousClosePrice=stock_page_doc.find('td',{'class':\"Ta(end) Fw(600) Lh(14px)\",'data-test':\"PREV_CLOSE-value\"}).text.replace(\",\",\"\")\n",
    "    Volume=stock_page_doc.find('td',{'class':\"Ta(end) Fw(600) Lh(14px)\",'data-test':\"TD_VOLUME-value\"}).text.replace(\",\",\"\")\n",
    "    \n",
    "    #Some of the stocks(ex.S&P) does not have market capital, using lambda function to replace such vaules with 0\n",
    "    MarketCap=(lambda x: x.text.replace(',','') if x != None else '0' )(stock_page_doc.find('td',{'class':\"Ta(end) Fw(600) Lh(14px)\",'data-test':\"MARKET_CAP-value\"}))\n",
    "    \n",
    "    ticker_dict={'Company':cName.replace(',',''),\n",
    "             'Symbol':ticker,\n",
    "             'Marketprice':float(MarketPrice),\n",
    "             'previousClosePrice':float(previousClosePrice),\n",
    "             'changeInPrice':round(float(MarketPrice)- float(previousClosePrice),2),\n",
    "             'Volume':int(Volume),\n",
    "             'MarketCap':MarketCap}\n",
    "    \n",
    "    #Return Dictionary with stock details\n",
    "    return ticker_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining 'write_csv' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(dict_items,file_name):\n",
    "    ''' \n",
    "       Accepts list of python dictionary with stock details and write it to a csv file\n",
    "       Prints success message upon completing the writing to the file\n",
    "    '''\n",
    "    \n",
    "    #open the file for writing\n",
    "    with open(file_name,'w') as f:\n",
    "        \n",
    "        #Get headers(keys) of the first dictionary from the list. Convert to a list, join each element of the list\n",
    "        #with ',' to form a string and write to the file.\n",
    "        headers=list(dict_items[0].keys())\n",
    "        f.write(\",\".join(headers)+\"\\n\")\n",
    "        \n",
    "        # For each Dictionary item, create a list with values and write it to the file\n",
    "        for dict_item in dict_items:\n",
    "            values=[]\n",
    "            for header in headers:\n",
    "                try:\n",
    "                    values.append(str(dict_item.get(header,''))) \n",
    "                except:\n",
    "                    pass\n",
    "            f.write(\",\".join(values)+\"\\n\")\n",
    "    \n",
    "    print(\"Writing to file '{}' completed\".format(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining 'verify_results' function to verify the output:\n",
    "- Display Sample Output\n",
    "- Get the number of records , and match it with the number of stock symbols passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_results(file_name):\n",
    "    ''' \n",
    "        This Function verifies the File Output.\n",
    "        Accepts file name as the parameter and displays sample output and row count.\n",
    "    '''\n",
    "    \n",
    "    # Create the dataFrame with the csv file\n",
    "    stocks_df=pd.read_csv(file_name)\n",
    "    \n",
    "    #print a record count of a single column\n",
    "    print('')\n",
    "    print('Checking Output written to the file')\n",
    "    print('---------------------------------------')\n",
    "    print(\"Number of records written to the file : \",stocks_df.count()[1])\n",
    "    print('')\n",
    "    #print a sample output of first 4 rows in the file alson with its headers\n",
    "    print(\"Sample Output : \")\n",
    "    display(stocks_df.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define 'scrape_stocks_info' function to bring all the fuctions together.\n",
    " - Gets the popular stock symbols\n",
    " - Pass each symbol as a parameter to get_ticker_details function and get stock details\n",
    " - build a list of dictionary with stock details\n",
    " - Write the information to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_stocks_info(num_stocks):\n",
    "    ''' \n",
    "      This function Accepts number of stocks to be processed and writes the stock information to a file\n",
    "    '''\n",
    "                       \n",
    "    #Gets List of popular stocks and passes them to the function 'get_ticker_details' one by one.\n",
    "    #This is return a list of dictionaries with stock details.\n",
    "    print(\"Start processing Stock symbols...\")\n",
    "    stocks_info=[get_ticker_details(ticker_name) for ticker_name in get_popular_stocks(num_stocks)]\n",
    "    print(\"End processing Stock symbols...\")\n",
    "    \n",
    "    # Pass the list of dictionies to the 'write_csv' function which writes it to the file.\n",
    "    file_name=str(num_stocks)+\"_most_popular_stocks_on_yahoo.csv\"\n",
    "    write_csv(stocks_info,file_name)\n",
    "    \n",
    "    #Verify Results:\n",
    "    verify_results(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call scrape_stocks_info function to get the stock details and write it to a file, This accepts number of stocks to process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing Stock symbols...\n",
      "Web Page:  https://companiesmarketcap.com/usa/largest-companies-in-the-usa-by-market-cap/?page=1/\n",
      "Web Page:  https://companiesmarketcap.com/usa/largest-companies-in-the-usa-by-market-cap/?page=2/\n",
      "Status code for https://finance.yahoo.com/quote/LBSI: 404\n",
      "End processing Stock symbols...\n",
      "Writing to file '200_most_popular_stocks_on_yahoo.csv' completed\n",
      "\n",
      "Checking Output written to the file\n",
      "---------------------------------------\n",
      "Number of records written to the file :  199\n",
      "\n",
      "Sample Output : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Marketprice</th>\n",
       "      <th>previousClosePrice</th>\n",
       "      <th>changeInPrice</th>\n",
       "      <th>Volume</th>\n",
       "      <th>MarketCap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>159.98</td>\n",
       "      <td>163.17</td>\n",
       "      <td>-3.19</td>\n",
       "      <td>73117951</td>\n",
       "      <td>2.611T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>280.89</td>\n",
       "      <td>289.86</td>\n",
       "      <td>-8.97</td>\n",
       "      <td>29489527</td>\n",
       "      <td>2.106T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2553.74</td>\n",
       "      <td>2642.44</td>\n",
       "      <td>-88.70</td>\n",
       "      <td>1071672</td>\n",
       "      <td>1.687T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon.com Inc.</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2753.43</td>\n",
       "      <td>2912.82</td>\n",
       "      <td>-159.39</td>\n",
       "      <td>3449112</td>\n",
       "      <td>1.401T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Company Symbol  Marketprice  previousClosePrice  \\\n",
       "0             Apple Inc.   AAPL       159.98              163.17   \n",
       "1  Microsoft Corporation   MSFT       280.89              289.86   \n",
       "2          Alphabet Inc.   GOOG      2553.74             2642.44   \n",
       "3        Amazon.com Inc.   AMZN      2753.43             2912.82   \n",
       "\n",
       "   changeInPrice    Volume MarketCap  \n",
       "0          -3.19  73117951    2.611T  \n",
       "1          -8.97  29489527    2.106T  \n",
       "2         -88.70   1071672    1.687T  \n",
       "3        -159.39   3449112    1.401T  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scrape_stocks_info(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"pramation/webscrape-top-n-stocks\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/pramation/webscrape-top-n-stocks\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/pramation/webscrape-top-n-stocks'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this project, we got the details of the 100 largest companies trading in the US stock exchanges.\n",
    "    \n",
    "This is accomplished by following the below outlined steps:\n",
    "1. Got the list of stock tickers of 100 largest companies from `companiesmarket.com` website. This is done using `requests` and `BeautifulSoup` libraries.\n",
    "2. For each stock symbol, We got the following  details from `https://finance.yahoo.com`:\n",
    "   * Today's price\n",
    "   * previous Day's price\n",
    "   * Change in Price\n",
    "   * Volume\n",
    "   * Company Name  \n",
    "   \n",
    "   We created a `python dictionary` to save all the details.<br>\n",
    "   This is done by using the function `get_ticker_details` and used `requests` and `BeautifulSoup` libraries.\n",
    "\n",
    "\n",
    "3. We built a list with the details of all the stock symbol from the above step.\n",
    "4. We wrote the data from above step to a `csv` file. This is done with `write_csv` function.\n",
    "5. Finally, we verified the data written to the file by doing the following:\n",
    "    * We read the data from csv file into a pandas DataFrame.\n",
    "    * Got the row count and compared it with the expected number.\n",
    "    * Displayed a sample output and visually verified it.\n",
    "6. Now this information can be used to get a sense of day's market trend of these stocks and possibly make a buy/sell decision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Work\n",
    "Now, with the foundation to scrape stock details in place. \n",
    "We can take this forward and schedule this to run every day and track the stock prices over a period of time. \n",
    "This Can be used to analyze the stock trends.\n",
    "This data can be further used to build Machine Learning models to do predictive analysis of the stock prices.\n",
    "In future, this can be used to analyze stocks traded in the stock exchanges across the globe.\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "1. Python offical documentation. https://docs.python.org/3/\n",
    "\n",
    "2. Requests library. https://pypi.org/project/requests/\n",
    "\n",
    "3. Beautiful Soup documentation. https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "4. Jovian, Introduction to Web Scraping. https://jovian.ai/aakashns/python-web-scraping-and-rest-api\n",
    "\n",
    "5. Pandas library documentation. https://pandas.pydata.org/docs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: Jovian lectures\n",
    "Future: This information can be tracked overtime and can be used to predict stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jovian.commit(files=['200_most_popular_stocks_on_yahoo.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}